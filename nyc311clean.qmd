---
title: "Creating an Arrow IPC file from the NYC 311 data"
author: 
  - name: Jun Yan
    affiliation: University of Connecticut
  - name: Douglas Bates
    affiliation: University of Wisconsin - Madison
jupyter: julia-1.9
execute:
  cache: true
  freeze: auto
---

## Abstract {.unnumbered}

We show conversion of a CSV file containing data on 311 service calls in New York City during March, 2023 to the [Arrow](https://arrow.apache.org) IPC (Inter-Process Communication) file format (also called the Feather V2 format), which can be read quickly and easily into several different data science environments.
This conversion is done in [Julia](https://julialang.org) but it could equally well have been done in a different language, if that is more convenient for the person doing the conversion.

# Reading the CSV file as a DataFrame

First we attach the packages to be used,

```{julia}
#| output: false
using Arrow, CSV, Dates, DataFrames
```

The first two lines of the CSV file are

```{julia}
#| panel: fill
open("./data/311_half_Mar_2023.csv", "r") do io # open the file
    println(readline(io))     # read and print the first line
    println(readline(io))     # read and print the next line
end;  # this open/do/end construction automatically closes the file when done
```

::: {.callout-note collapse="false"}
### Need to scroll right to see the whole output line

The output from this code block has very long lines.
You will need to scroll right in the output to read it all.

Note that the character on the right of the title bar for callout blocks like this, currently a `v`-shape for this block, is a toggle to show or collapse the contents of the block.
Try clicking on that character to collapse the contents of the block.

In what follows the callout blocks are initially collapsed and you must click on the `>` character on the right end of the title bar to show the contents.
:::



We now have enough information, such as the date-time format used, to do an initial conversion of the CSV file to a `DataFrame`, using several optional arguments to customize the process.
(Details about each of these optional arguments are given in callout blocks below.)

```{julia}
df = CSV.read(
    "./data/311_half_Mar_2023.csv",  # file name
    DataFrame,           # output table type
    normalizenames=true, # convert column names to valid symbols
    missingstring=[      # strings that are used to indicate missing values
        "",
        "Unspecified",
        "unspecified",
        "Unknown",
        "unknown",
        "NA",
    ],
    dateformat=dateformat"m/d/Y I:M:S p", # DateTimes look like this
    downcast=true,       # use smallest type of Int that can represent the column 
    stripwhitespace=true # strip leading and trailing whitespace 
)
```

:::{.callout-note collapse="true"}
### normalizenames
Convert the column names from the CSV file into a form that can be parsed as a `Symbol` in `Julia`.
In particular, strip whitespace at the beginning and end of the name and replace embedded blanks or `.` characters by underscores.

Columns of a DataFrame (and other type of tables) are usually extracted as "properties" of the table, either as, e.g. `getproperty(df, :Unique_Key)`, or, more commonly, with the dot operator as, e.g. `df.Unique_Key`.
The expression `:Unique_Key` or the right operand of `df.Unique_Key` evaluates to a Symbol.
If the column name has an embedded blank or `.` this form cannot be used and the name must be quoted, either as `Symbol("Unique.Key")` or `var"Unique.Key"`.

Thus it is an advantage to rewrite the column names so that each name can be used "as is" with the dot operator.
:::

:::{.callout-note collapse="true"}
### missingstring
Enumerate the various forms of missing data indicators used in the file.
Completing this list is often a process of trial-and-error.
:::

:::{.callout-note collapse="true"}
### dateformat
Provide a `Dates.DateFormat` object that will be applied to text columns if they match the pattern, converting to `DateTime` values.

The construction `dateformat"..."` is a call to a "string macro" in Julia.
That is, it is just a shorthand for replacing the string with the `Dates.DateFormat` object created from the string.
:::

:::{.callout-note collapse="true"}
### downcast
For columns of integer values, choose the smallest integer type, such as `Int8`, `Int16`, etc., that can represent all the values in the column.
:::

# Validity checking

## Review the storage type for each column

In the output (remember, you must scroll horizontally to see it all) there is a description of the type of the elements of the column directly under the column name.
A type name that ends in `?` indicates that missing values are present in the column.
Thus, for example, the `Unique_Key` is designated `Int32` meaning the values are stored as 32-bit signed integers with no missing values.
The `Created_Date` column, designated `DateTime`, is a `DateTime` column with no missing values but the `Closed_Date`, designated `DateTime?`, is also a `DateTime`, but can (and does) have missing values.

Some columns are designated as `String` whereas others are designated as `String7` or `String15`.
These are storage-saving representations used when the whole column consists of short character strings.

There is an anomaly in these short strings for the `Agency` column.
The `Agency` acronyms should be 5 characters at most, which would be stored as `String7`, but they are stored as `String15`.

To see why, we check the unique combinations of the `Agency` and `Agency_Name` columns

```{julia}
unique(select(df, :Agency, :Agency_Name))
```

These columns should be in one-to-one correspondence but they are not.

At this point we would need to check with the data providers to determine why two different `Agency` designations are used for the "Department of Environmental Protection".

The other problem shown in the types is that the values in the `Incident_Zip` column are stored as `String7?` when they should be `Int32?`.

Checking the unique values

```{julia}
sort(unique(df.Incident_Zip))
```

shows the problem is that someone got creative and used `na` as a missing value indicator.

Recreate the DataFrame with `"na"` in the `missingstring` vector

```{julia}
df = CSV.read(
    "./data/311_half_Mar_2023.csv",  # file name
    DataFrame,           # output table type
    normalizenames=true, # convert column names to valid symbols
    missingstring=[      # strings that are used to indicate missing vals
        "",
        "Unspecified",
        "unspecified",
        "Unknown",
        "unknown",
        "NA",
        "na",
    ],
    dateformat=dateformat"m/d/Y I:M:S p", # DateTimes look like this
    downcast=true,       # use smallest type of Int that can represent the column 
    stripwhitespace=true # strip leading and trailing whitespace 
)
```

## Further checks

### Are the `Unique_Key` values unique?
```{julia}
length(unique(df.Unique_Key)) == nrow(df)
```

### Are the `Created_Date` values all from March, 2023?

```{julia}
extrema(df.Created_Date)
```

### Are the `Closed_Date` values in the expected range?

```{julia}
extrema(skipmissing(df.Closed_Date))
```

:::{.callout-note collapse="true"}
### use of skipmissing
There are missing values in the `Closed_Date` column which must be skipped when evaluating the extremes.
:::

Now we can see a problem with the record giving the earliest `Closed_Date` because it is before the `Created_Date` range.

We save the indicators of rows with early closing or immediate closing for later manual checking.

```{julia}
earlyclosing = @. !ismissing(df.Closed_Date) && (df.Closed_Date < df.Created_Date)
immediateclosing = @. !ismissing(df.Closed_Date) && (df.Closed_Date == df.Created_Date)
(early = count(earlyclosing), immediate = count(immediateclosing))
```

:::{.callout-note collapse="true"}
### What does `@.` do?

[Dot vectorization](https://docs.julialang.org/en/v1/manual/functions/#man-vectorized) in Julia provides "syntactic sugar" to vectorize a scalar operation.
Prefacing an expression with `@.` applies dot vectorization to all the function calls and operators in the expression. 
:::

If we want to examine the rows with these characteristics we index the rows with the `BitVector` created from the logical expression.
To see the first 3 rows with early closings

```{julia}
earlyfrm = df[earlyclosing, :]
first(earlyfrm, 3)
```

:::{.callout-note collapse="true"}
### Use of `:` as an index indicates all values for that axis
In this case the use of `:` as the second index indicates that all the columns should be included in the subset.
:::

These three are from the "Department of Transport" and, in fact, all rows with early closing dates are from the DOT

```{julia}
unique(select(earlyfrm, :Agency, :Agency_Name))
```

## Is Location redundant if Latitude and Longitude are given?

This is a tricky question because the values of `Latitude` and `Longitude` are stored to 17 significant digits, which is much more accuracy than could possibly be measured, but equality comparisons, either as floating-point numbers or as strings with 17 significant digits, would require an exact match.

To check for consistency we need to convert the `Location` to a `Latitude-Longitude` pair of floating point numbers then check for approximate equality of these values to the recorded `Latitude` and `Longitude`.
We'll leave that as an exercise for the reader and just assure you that the `Location` column is redundant and can be dropped.

# Saving the dataset as an Arrow IPC file

We use `Arrow.write` to write the dataframe in the Arrow IPC format.

```{julia}
#| output: false
fn = Arrow.write(    # returns the file name
    "./data/311_half_Mar_2023.arrow",
    select(df, Not(:Location)),
)
```

The Arrow file is less than one third the size of the original CSV file but contains much more specificity about the data types and representations.
Furthermore it can be read into other data science environments without needing to tinker with arguments to CSV file-reading functions.

The Arrow IPC format and the `Arrow.write` function in the Julia package allow for optional compression of the contents using `lz4` or `zstd` compression, if further reduction of the file size is desired.
The downside of compression is that an uncompressed file can be memory-mapped, allowing for extremely fast input, whereas the compressed files must be decompressed into memory.

This file can be read into Julia

```{julia}
tbl = Arrow.Table(fn)
```

or R
```r
> tibble::glimpse(arrow::read_ipc_file("./data/311_half_Mar_2023.arrow"))
Rows: 125,826
Columns: 45
$ Unique_Key                     <int> 57000688, 56993837, 57049479, 57056381,…
$ Created_Date                   <dttm> 2023-03-09 09:05:25, 2023-03-08 15:27:…
$ Closed_Date                    <dttm> 2023-03-13 03:21:11, 2023-05-03 02:17:…
$ Agency                         <fct> DOE, TLC, HPD, NYPD, DOB, DPR, DOT, NYP…
$ Agency_Name                    <fct> Department of Education, Taxi and Limou…
$ Complaint_Type                 <fct> School Maintenance, For Hire Vehicle Co…
$ Descriptor                     <chr> "Other School Condition", "Driver Compl…
$ Location_Type                  <fct> School, Street, RESIDENTIAL BUILDING, S…
$ Incident_Zip                   <int> NA, 10075, 10459, 10455, 11365, 11691, …
$ Incident_Address               <chr> NA, "995 MADISON AVENUE", "1010 BRYANT …
$ Street_Name                    <chr> NA, "MADISON AVENUE", "BRYANT AVENUE", …
$ Cross_Street_1                 <chr> NA, "EAST   77 STREET", NA, "EAST  147 …
$ Cross_Street_2                 <chr> NA, "EAST   78 STREET", NA, "EAST  149 …
$ Intersection_Street_1          <chr> NA, "EAST   77 STREET", NA, "EAST  147 …
$ Intersection_Street_2          <chr> NA, "EAST   78 STREET", NA, "EAST  149 …
$ Address_Type                   <fct> NA, ADDRESS, ADDRESS, ADDRESS, ADDRESS,…
$ City                           <fct> NA, NEW YORK, BRONX, BRONX, FRESH MEADO…
$ Landmark                       <chr> NA, "MADISON AVENUE", NA, "UNION AVENUE…
$ Facility_Type                  <fct> NA, NA, NA, NA, NA, NA, N/A, NA, NA, NA…
$ Status                         <fct> Closed, Closed, Closed, Closed, Assigne…
$ Due_Date                       <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
$ Resolution_Description         <fct> "The Department of Education determined…
$ Resolution_Action_Updated_Date <dttm> 2023-03-13 03:21:17, 2023-05-03 02:17:…
$ Community_Board                <fct> Unspecified BROOKLYN, 08 MANHATTAN, 02 …
$ BBL                            <int64> NA, 1013927501, 2027560001, 202582004…
$ Borough                        <fct> BROOKLYN, MANHATTAN, BRONX, BRONX, QUEE…
$ X_Coordinate_State_Plane_      <int> 989013, 994507, 1015090, 1010420, 10388…
$ Y_Coordinate_State_Plane_      <int> 173052, 221687, 239359, 235260, 206195,…
$ Open_Data_Channel_Type         <fct> PHONE, ONLINE, PHONE, MOBILE, UNKNOWN, …
$ Park_Facility_Name             <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
$ Park_Borough                   <fct> BROOKLYN, MANHATTAN, BRONX, BRONX, QUEE…
$ Vehicle_Type                   <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
$ Taxi_Company_Borough           <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
$ Taxi_Pick_Up_Location          <chr> NA, "995 MADISON AVENUE, MANHATTAN (NEW…
$ Bridge_Highway_Name            <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
$ Bridge_Highway_Direction       <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
$ Road_Ramp                      <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
$ Bridge_Highway_Segment         <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
$ Latitude                       <dbl> 40.64166, 40.77515, 40.82361, 40.81237,…
$ Longitude                      <dbl> -73.98284, -73.96297, -73.88857, -73.90…
$ Zip_Codes                      <int> 17620, 10092, 10937, 10933, 14507, 2052…
$ Community_Districts            <int> 2, 23, 8, 49, 25, 51, NA, 26, 5, 24, 47…
$ Borough_Boundaries             <int> 2, 4, 5, 5, 3, 3, NA, 3, 2, 5, 4, 5, 3,…
$ City_Council_Districts         <int> 27, 51, 43, 35, 24, 47, NA, 16, 8, 29, …
$ Police_Precincts               <int> 39, 11, 24, 23, 65, 59, NA, 69, 38, 34,…
```
:::{.callout-note collapse="true"}
### R applies a time zone to the datetime values
The R `arrow` package appears to read the DateTime values as if they are UTC values then prints them in the local time zone.
:::

or in Python with `pyarrow` or with [polars](https://pola.rs).
(Note that the Arrow IPC format is called `feather` in the `pyarrow` package.)
```python
>>> import pyarrow.feather as fea
>>> import polars as pl
>>> fea.read_table('./data/311_half_Mar_2023.arrow')
pyarrow.Table
Unique_Key: int32 not null
Created_Date: timestamp[ms] not null
Closed_Date: timestamp[ms]
Agency: dictionary<values=string, indices=int8, ordered=0> not null
Agency_Name: dictionary<values=string, indices=int8, ordered=0> not null
Complaint_Type: dictionary<values=string, indices=int16, ordered=0> not null
Descriptor: string
Location_Type: dictionary<values=string, indices=int8, ordered=0>
Incident_Zip: int32
Incident_Address: string
Street_Name: string
Cross_Street_1: string
Cross_Street_2: string
Intersection_Street_1: string
Intersection_Street_2: string
Address_Type: dictionary<values=string, indices=int8, ordered=0>
City: dictionary<values=string, indices=int8, ordered=0>
Landmark: string
Facility_Type: dictionary<values=string, indices=int8, ordered=0>
Status: dictionary<values=string, indices=int8, ordered=0>
Due_Date: timestamp[ms]
Resolution_Description: dictionary<values=string, indices=int16, ordered=0>
Resolution_Action_Updated_Date: timestamp[ms]
Community_Board: dictionary<values=string, indices=int8, ordered=0> not null
BBL: int64
Borough: dictionary<values=string, indices=int8, ordered=0>
X_Coordinate_State_Plane_: int32
Y_Coordinate_State_Plane_: int32
Open_Data_Channel_Type: dictionary<values=string, indices=int8, ordered=0> not null
Park_Facility_Name: dictionary<values=string, indices=int16, ordered=0>
Park_Borough: dictionary<values=string, indices=int8, ordered=0>
Vehicle_Type: dictionary<values=string, indices=int8, ordered=0>
Taxi_Company_Borough: dictionary<values=string, indices=int8, ordered=0>
Taxi_Pick_Up_Location: string
Bridge_Highway_Name: dictionary<values=string, indices=int8, ordered=0>
Bridge_Highway_Direction: dictionary<values=string, indices=int8, ordered=0>
Road_Ramp: dictionary<values=string, indices=int8, ordered=0>
Bridge_Highway_Segment: dictionary<values=string, indices=int16, ordered=0>
Latitude: double
Longitude: double
Zip_Codes: int16
Community_Districts: int8
Borough_Boundaries: int8
City_Council_Districts: int8
Police_Precincts: int8
----
Unique_Key: [[57000688,56993837,57049479,57056381,57023097,...,57116487,56954525,57132547,57102740,56950149]]
Created_Date: [[2023-03-09 15:05:25.000,2023-03-08 21:27:34.000,2023-03-15 19:26:41.000,2023-03-16 23:58:53.000,2023-03-12 15:15:54.000,...,2023-03-22 17:47:08.000,2023-03-04 16:23:00.000,2023-03-24 21:57:44.000,2023-03-21 05:10:12.000,2023-03-04 00:27:00.000]]
Closed_Date: [[2023-03-13 08:21:11.000,2023-05-03 07:17:20.000,2023-03-21 21:16:53.000,2023-03-17 02:44:31.000,2023-04-19 00:00:00.000,...,null,2023-03-08 10:50:00.000,2023-03-24 23:18:11.000,2023-03-21 05:16:30.000,2023-03-04 10:15:00.000]]
Agency: [  -- dictionary:
["DOE","TLC","HPD","NYPD","DOB",...,"DHS","EDC","DCA","NYC311-PRD","OTI"]  -- indices:
[0,1,2,3,4,...,5,7,3,3,6]]
Agency_Name: [  -- dictionary:
["Department of Education","Taxi and Limousine Commission","Department of Housing Preservation and Development","New York City Police Department","Department of Buildings",...,"Department of Sanitation","Department of Homeless Services","Economic Development Corporation","Department of Consumer Affairs","Office of Technology and Innovation"]  -- indices:
[0,1,2,3,4,...,5,7,3,3,6]]
Complaint_Type: [  -- dictionary:
["School Maintenance","For Hire Vehicle Complaint","UNSANITARY CONDITION","Illegal Parking","Building/Use",...,"Building Drinking Water Tank","Taxi Licensee Complaint","Peeling Paint","Green Taxi Report","Bus Stop Shelter Placement"]  -- indices:
[0,1,2,3,4,...,30,80,3,7,16]]
Descriptor: [["Other School Condition","Driver Complaint - Non Passenger","PESTS","Posted Parking Sign Violation","Illegal Conversion Of Residential Building/Space",...,"For One Address","Lead Kit Request (Residential) (L10)","Commercial Overnight Parking","Loud Music/Party","Post"]]
Location_Type: [  -- dictionary:
["School","Street","RESIDENTIAL BUILDING","Street/Sidewalk",null,...,"Building Entrance","Public Stairs","Cafeteria - Public School","Commercial","Speed Reducer"]  -- indices:
[0,1,2,3,null,...,1,null,3,6,null]]
Incident_Zip: [[null,10075,10459,10455,11365,...,null,null,null,null,null]]
Incident_Address: [[null,"995 MADISON AVENUE","1010 BRYANT AVENUE","541 UNION AVENUE","69-35 166 STREET",...,"209 WEST   93 STREET","220 WEST   16 STREET","38 STERLING AVENUE","243 HENRY STREET",null]]
...
>>> pl.read_ipc('./data/311_half_Mar_2023.arrow', use_pyarrow=True)
shape: (125_826, 45)
┌──────────┬────────────┬───────────┬────────┬───┬────────────┬────────────┬────────────┬────────────┐
│ Unique_K ┆ Created_Da ┆ Closed_Da ┆ Agency ┆ … ┆ Community_ ┆ Borough_Bo ┆ City_Counc ┆ Police_Pre │
│ ey       ┆ te         ┆ te        ┆ ---    ┆   ┆ Districts  ┆ undaries   ┆ il_Distric ┆ cincts     │
│ ---      ┆ ---        ┆ ---       ┆ cat    ┆   ┆ ---        ┆ ---        ┆ ts         ┆ ---        │
│ i32      ┆ datetime[m ┆ datetime[ ┆        ┆   ┆ i8         ┆ i8         ┆ ---        ┆ i8         │
│          ┆ s]         ┆ ms]       ┆        ┆   ┆            ┆            ┆ i8         ┆            │
╞══════════╪════════════╪═══════════╪════════╪═══╪════════════╪════════════╪════════════╪════════════╡
│ 57000688 ┆ 2023-03-09 ┆ 2023-03-1 ┆ DOE    ┆ … ┆ 2          ┆ 2          ┆ 27         ┆ 39         │
│          ┆ 15:05:25   ┆ 3         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 08:21:11  ┆        ┆   ┆            ┆            ┆            ┆            │
│ 56993837 ┆ 2023-03-08 ┆ 2023-05-0 ┆ TLC    ┆ … ┆ 23         ┆ 4          ┆ 51         ┆ 11         │
│          ┆ 21:27:34   ┆ 3         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 07:17:20  ┆        ┆   ┆            ┆            ┆            ┆            │
│ 57049479 ┆ 2023-03-15 ┆ 2023-03-2 ┆ HPD    ┆ … ┆ 8          ┆ 5          ┆ 43         ┆ 24         │
│          ┆ 19:26:41   ┆ 1         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 21:16:53  ┆        ┆   ┆            ┆            ┆            ┆            │
│ 57056381 ┆ 2023-03-16 ┆ 2023-03-1 ┆ NYPD   ┆ … ┆ 49         ┆ 5          ┆ 35         ┆ 23         │
│          ┆ 23:58:53   ┆ 7         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 02:44:31  ┆        ┆   ┆            ┆            ┆            ┆            │
│ …        ┆ …          ┆ …         ┆ …      ┆ … ┆ …          ┆ …          ┆ …          ┆ …          │
│ 56954525 ┆ 2023-03-04 ┆ 2023-03-0 ┆ DEP    ┆ … ┆ 12         ┆ 4          ┆ 10         ┆ 6          │
│          ┆ 16:23:00   ┆ 8         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 10:50:00  ┆        ┆   ┆            ┆            ┆            ┆            │
│ 57132547 ┆ 2023-03-24 ┆ 2023-03-2 ┆ NYPD   ┆ … ┆ 30         ┆ 1          ┆ 14         ┆ 76         │
│          ┆ 21:57:44   ┆ 4         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 23:18:11  ┆        ┆   ┆            ┆            ┆            ┆            │
│ 57102740 ┆ 2023-03-21 ┆ 2023-03-2 ┆ NYPD   ┆ … ┆ 70         ┆ 4          ┆ 32         ┆ 4          │
│          ┆ 05:10:12   ┆ 1         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 05:16:30  ┆        ┆   ┆            ┆            ┆            ┆            │
│ 56950149 ┆ 2023-03-04 ┆ 2023-03-0 ┆ DOT    ┆ … ┆ 41         ┆ 3          ┆ 16         ┆ 61         │
│          ┆ 00:27:00   ┆ 4         ┆        ┆   ┆            ┆            ┆            ┆            │
│          ┆            ┆ 10:15:00  ┆        ┆   ┆            ┆            ┆            ┆            │
└──────────┴────────────┴───────────┴────────┴───┴────────────┴────────────┴────────────┴────────────┘
```

The columns that are described as `<fct>` in the `glimpse` output from R (and `dictionary` in the output from `fea.read_table` and `cat` (for "categorical") in the Polars data frame) are `factor` representations, consisting of a (short) vector of the unique values, called the `levels` of the factor, and an integer vector of indices into the levels.
The conversion of a column of character strings, many of which are repetitions, to a
factor or "dictionary encoded" representation, can result in considerable storage saving, at the expense of a trivial amount of processing.
For example, storing the `Agency_Name` as a vector of strings takes about 34 MB but, after dictionary encoding, it takes up about 1/8 MB.

The output from `fea.read_table` is often the most informative representation of the structure of the table.
